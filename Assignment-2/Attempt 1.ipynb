{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 2500\n",
    "## Module Assignment 2 - Cleaning Data\n",
    "For this assignment, I am using a dataset that quantifies and measures the different phoenitics of different words and languages. The website to the data can be found [here](http://www.phonetics.ucla.edu/voiceproject/voice.html). This dataset is a candidate for cleaning because of its shape. Namely, the data is spread wide and thingwith multiple columns for time series data. This can be changed to be shorter and deeper, reducing the number of columns and making it easier to gain insights from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data, hoping that the warning will not give us any trouble. Will depend on which columsn we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Voice_Master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an idea of what the data is describing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>0=do not use</th>\n",
       "      <th>Label</th>\n",
       "      <th>Language</th>\n",
       "      <th>Dialect/Village</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Speaker #</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Lang_Spk</th>\n",
       "      <th>Phonation</th>\n",
       "      <th>...</th>\n",
       "      <th>sB4_mean</th>\n",
       "      <th>sB4_means001</th>\n",
       "      <th>sB4_means002</th>\n",
       "      <th>sB4_means003</th>\n",
       "      <th>sB4_means004</th>\n",
       "      <th>sB4_means005</th>\n",
       "      <th>sB4_means006</th>\n",
       "      <th>sB4_means007</th>\n",
       "      <th>sB4_means008</th>\n",
       "      <th>sB4_means009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>F19May20_sure_normal.mat</td>\n",
       "      <td>0 end</td>\n",
       "      <td>r</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>F19</td>\n",
       "      <td>English_F19</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>263.529</td>\n",
       "      <td>217.219</td>\n",
       "      <td>272.275</td>\n",
       "      <td>230.260</td>\n",
       "      <td>215.393</td>\n",
       "      <td>178.683</td>\n",
       "      <td>158.294</td>\n",
       "      <td>209.815</td>\n",
       "      <td>348.863</td>\n",
       "      <td>542.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>F19May20_sure_normal.mat</td>\n",
       "      <td>0 end</td>\n",
       "      <td>r</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>F19</td>\n",
       "      <td>English_F19</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>375.086</td>\n",
       "      <td>354.539</td>\n",
       "      <td>448.949</td>\n",
       "      <td>254.102</td>\n",
       "      <td>159.089</td>\n",
       "      <td>220.819</td>\n",
       "      <td>198.345</td>\n",
       "      <td>227.356</td>\n",
       "      <td>592.842</td>\n",
       "      <td>908.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>F19May20_sure_normal.mat</td>\n",
       "      <td>0</td>\n",
       "      <td>r</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>F19</td>\n",
       "      <td>English_F19</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>295.344</td>\n",
       "      <td>407.098</td>\n",
       "      <td>357.500</td>\n",
       "      <td>242.458</td>\n",
       "      <td>224.664</td>\n",
       "      <td>200.499</td>\n",
       "      <td>192.645</td>\n",
       "      <td>229.259</td>\n",
       "      <td>363.865</td>\n",
       "      <td>434.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>F1July22_sure_normal.mat</td>\n",
       "      <td>0 end</td>\n",
       "      <td>r</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>F1</td>\n",
       "      <td>English_F1</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>277.880</td>\n",
       "      <td>131.692</td>\n",
       "      <td>410.788</td>\n",
       "      <td>366.203</td>\n",
       "      <td>183.711</td>\n",
       "      <td>213.710</td>\n",
       "      <td>246.977</td>\n",
       "      <td>328.101</td>\n",
       "      <td>265.039</td>\n",
       "      <td>357.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>F1July22_sure_normal.mat</td>\n",
       "      <td>0 end</td>\n",
       "      <td>r</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>F1</td>\n",
       "      <td>English_F1</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>335.320</td>\n",
       "      <td>209.534</td>\n",
       "      <td>376.419</td>\n",
       "      <td>357.762</td>\n",
       "      <td>191.279</td>\n",
       "      <td>250.888</td>\n",
       "      <td>322.978</td>\n",
       "      <td>439.648</td>\n",
       "      <td>573.923</td>\n",
       "      <td>291.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Filename 0=do not use Label Language Dialect/Village Sex  \\\n",
       "0  F19May20_sure_normal.mat        0 end     r  English             NaN   F   \n",
       "1  F19May20_sure_normal.mat        0 end     r  English             NaN   F   \n",
       "2  F19May20_sure_normal.mat            0     r  English             NaN   F   \n",
       "3  F1July22_sure_normal.mat        0 end     r  English             NaN   F   \n",
       "4  F1July22_sure_normal.mat        0 end     r  English             NaN   F   \n",
       "\n",
       "  Speaker # Speaker     Lang_Spk Phonation  ... sB4_mean sB4_means001  \\\n",
       "0        19     F19  English_F19         M  ...  263.529      217.219   \n",
       "1        19     F19  English_F19         M  ...  375.086      354.539   \n",
       "2        19     F19  English_F19         M  ...  295.344      407.098   \n",
       "3         1      F1   English_F1         M  ...  277.880      131.692   \n",
       "4         1      F1   English_F1         M  ...  335.320      209.534   \n",
       "\n",
       "  sB4_means002 sB4_means003  sB4_means004 sB4_means005  sB4_means006  \\\n",
       "0      272.275      230.260       215.393      178.683       158.294   \n",
       "1      448.949      254.102       159.089      220.819       198.345   \n",
       "2      357.500      242.458       224.664      200.499       192.645   \n",
       "3      410.788      366.203       183.711      213.710       246.977   \n",
       "4      376.419      357.762       191.279      250.888       322.978   \n",
       "\n",
       "  sB4_means007 sB4_means008 sB4_means009  \n",
       "0      209.815      348.863      542.583  \n",
       "1      227.356      592.842      908.053  \n",
       "2      229.259      363.865      434.302  \n",
       "3      328.101      265.039      357.186  \n",
       "4      439.648      573.923      291.340  \n",
       "\n",
       "[5 rows x 474 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>0=do not use</th>\n",
       "      <th>Label</th>\n",
       "      <th>Language</th>\n",
       "      <th>Dialect/Village</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Speaker #</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Lang_Spk</th>\n",
       "      <th>Phonation</th>\n",
       "      <th>...</th>\n",
       "      <th>sB4_mean</th>\n",
       "      <th>sB4_means001</th>\n",
       "      <th>sB4_means002</th>\n",
       "      <th>sB4_means003</th>\n",
       "      <th>sB4_means004</th>\n",
       "      <th>sB4_means005</th>\n",
       "      <th>sB4_means006</th>\n",
       "      <th>sB4_means007</th>\n",
       "      <th>sB4_means008</th>\n",
       "      <th>sB4_means009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16828</td>\n",
       "      <td>zhangyuanlin_95.mat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tcjiu_11</td>\n",
       "      <td>Miao</td>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>M9</td>\n",
       "      <td>Miao_M9</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>327.336</td>\n",
       "      <td>378.439</td>\n",
       "      <td>250.337</td>\n",
       "      <td>134.721</td>\n",
       "      <td>169.282</td>\n",
       "      <td>323.310</td>\n",
       "      <td>432.931</td>\n",
       "      <td>339.113</td>\n",
       "      <td>414.309</td>\n",
       "      <td>505.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16829</td>\n",
       "      <td>zhangyuanlin_96.mat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ji_11</td>\n",
       "      <td>Miao</td>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>M9</td>\n",
       "      <td>Miao_M9</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>235.652</td>\n",
       "      <td>314.088</td>\n",
       "      <td>341.231</td>\n",
       "      <td>282.147</td>\n",
       "      <td>134.731</td>\n",
       "      <td>251.197</td>\n",
       "      <td>221.899</td>\n",
       "      <td>187.067</td>\n",
       "      <td>230.593</td>\n",
       "      <td>150.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16830</td>\n",
       "      <td>zhangyuanlin_96.mat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ji_11</td>\n",
       "      <td>Miao</td>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>M9</td>\n",
       "      <td>Miao_M9</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>209.277</td>\n",
       "      <td>434.323</td>\n",
       "      <td>346.341</td>\n",
       "      <td>103.444</td>\n",
       "      <td>92.883</td>\n",
       "      <td>199.917</td>\n",
       "      <td>207.126</td>\n",
       "      <td>172.638</td>\n",
       "      <td>112.100</td>\n",
       "      <td>214.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16831</td>\n",
       "      <td>zhangyuanlin_97.mat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ji_11</td>\n",
       "      <td>Miao</td>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>M9</td>\n",
       "      <td>Miao_M9</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>287.905</td>\n",
       "      <td>270.581</td>\n",
       "      <td>315.447</td>\n",
       "      <td>341.351</td>\n",
       "      <td>156.315</td>\n",
       "      <td>392.650</td>\n",
       "      <td>287.414</td>\n",
       "      <td>175.332</td>\n",
       "      <td>246.023</td>\n",
       "      <td>407.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16832</td>\n",
       "      <td>zhangyuanlin_97.mat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ji_11</td>\n",
       "      <td>Miao</td>\n",
       "      <td>Black</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>M9</td>\n",
       "      <td>Miao_M9</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>194.415</td>\n",
       "      <td>290.551</td>\n",
       "      <td>162.938</td>\n",
       "      <td>170.563</td>\n",
       "      <td>218.658</td>\n",
       "      <td>334.173</td>\n",
       "      <td>182.692</td>\n",
       "      <td>88.381</td>\n",
       "      <td>123.813</td>\n",
       "      <td>178.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 474 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filename 0=do not use     Label Language Dialect/Village  \\\n",
       "16828  zhangyuanlin_95.mat          NaN  tcjiu_11     Miao           Black   \n",
       "16829  zhangyuanlin_96.mat          NaN     ji_11     Miao           Black   \n",
       "16830  zhangyuanlin_96.mat          NaN     ji_11     Miao           Black   \n",
       "16831  zhangyuanlin_97.mat          NaN     ji_11     Miao           Black   \n",
       "16832  zhangyuanlin_97.mat          NaN     ji_11     Miao           Black   \n",
       "\n",
       "      Sex Speaker # Speaker Lang_Spk Phonation  ... sB4_mean sB4_means001  \\\n",
       "16828   M         9      M9  Miao_M9         C  ...  327.336      378.439   \n",
       "16829   M         9      M9  Miao_M9         C  ...  235.652      314.088   \n",
       "16830   M         9      M9  Miao_M9         C  ...  209.277      434.323   \n",
       "16831   M         9      M9  Miao_M9         C  ...  287.905      270.581   \n",
       "16832   M         9      M9  Miao_M9         C  ...  194.415      290.551   \n",
       "\n",
       "      sB4_means002 sB4_means003  sB4_means004 sB4_means005  sB4_means006  \\\n",
       "16828      250.337      134.721       169.282      323.310       432.931   \n",
       "16829      341.231      282.147       134.731      251.197       221.899   \n",
       "16830      346.341      103.444        92.883      199.917       207.126   \n",
       "16831      315.447      341.351       156.315      392.650       287.414   \n",
       "16832      162.938      170.563       218.658      334.173       182.692   \n",
       "\n",
       "      sB4_means007 sB4_means008 sB4_means009  \n",
       "16828      339.113      414.309      505.629  \n",
       "16829      187.067      230.593      150.794  \n",
       "16830      172.638      112.100      214.463  \n",
       "16831      175.332      246.023      407.812  \n",
       "16832       88.381      123.813      178.586  \n",
       "\n",
       "[5 rows x 474 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape data\n",
    "The value that we interested in are the different quantitative metrics that describe the signal of the spoken word. There are several values (shrF0_mean, H1_mean, H2_mean, H4_mean, H1-H2_mean etc), and each of these values has a corresponding column that represents the mean of that value at a specific time interval. The time intervals range from 001 to 009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H1c_mean', 'H1c_means001', 'H1c_means002', 'H1c_means003', 'H1c_means004', 'H1c_means005', 'H1c_means006', 'H1c_means007', 'H1c_means008', 'H1c_means009', 'H2c_mean', 'H2c_means001', 'H2c_means002', 'H2c_means003', 'H2c_means004', 'H2c_means005', 'H2c_means006', 'H2c_means007', 'H2c_means008', 'H2c_means009', 'H4c_mean', 'H4c_means001', 'H4c_means002', 'H4c_means003', 'H4c_means004', 'H4c_means005', 'H4c_means006', 'H4c_means007', 'H4c_means008', 'H4c_means009', 'A1c_mean', 'A1c_means001', 'A1c_means002', 'A1c_means003', 'A1c_means004', 'A1c_means005', 'A1c_means006', 'A1c_means007', 'A1c_means008', 'A1c_means009', 'A2c_mean', 'A2c_means001', 'A2c_means002', 'A2c_means003', 'A2c_means004', 'A2c_means005', 'A2c_means006', 'A2c_means007', 'A2c_means008', 'A2c_means009', 'A3c_mean', 'A3c_means001', 'A3c_means002', 'A3c_means003', 'A3c_means004', 'A3c_means005', 'A3c_means006', 'A3c_means007', 'A3c_means008', 'A3c_means009', 'H1H2c_mean', 'H1H2c_means001', 'H1H2c_means002', 'H1H2c_means003', 'H1H2c_means004', 'H1H2c_means005', 'H1H2c_means006', 'H1H2c_means007', 'H1H2c_means008', 'H1H2c_means009', 'H2H4c_mean', 'H2H4c_means001', 'H2H4c_means002', 'H2H4c_means003', 'H2H4c_means004', 'H2H4c_means005', 'H2H4c_means006', 'H2H4c_means007', 'H2H4c_means008', 'H2H4c_means009', 'H1A1c_mean', 'H1A1c_means001', 'H1A1c_means002', 'H1A1c_means003', 'H1A1c_means004', 'H1A1c_means005', 'H1A1c_means006', 'H1A1c_means007', 'H1A1c_means008', 'H1A1c_means009', 'H1A2c_mean', 'H1A2c_means001', 'H1A2c_means002', 'H1A2c_means003', 'H1A2c_means004', 'H1A2c_means005', 'H1A2c_means006', 'H1A2c_means007', 'H1A2c_means008', 'H1A2c_means009', 'H1A3c_mean', 'H1A3c_means001', 'H1A3c_means002', 'H1A3c_means003', 'H1A3c_means004', 'H1A3c_means005', 'H1A3c_means006', 'H1A3c_means007', 'H1A3c_means008', 'H1A3c_means009', 'shrF0_mean', 'shrF0_means001', 'shrF0_means002', 'shrF0_means003', 'shrF0_means004', 'shrF0_means005', 'shrF0_means006', 'shrF0_means007', 'shrF0_means008', 'shrF0_means009', 'H1u_mean', 'H1u_means001', 'H1u_means002', 'H1u_means003', 'H1u_means004', 'H1u_means005', 'H1u_means006', 'H1u_means007', 'H1u_means008', 'H1u_means009', 'H2u_mean', 'H2u_means001', 'H2u_means002', 'H2u_means003', 'H2u_means004', 'H2u_means005', 'H2u_means006', 'H2u_means007', 'H2u_means008', 'H2u_means009', 'H4u_mean', 'H4u_means001', 'H4u_means002', 'H4u_means003', 'H4u_means004', 'H4u_means005', 'H4u_means006', 'H4u_means007', 'H4u_means008', 'H4u_means009', 'A1u_mean', 'A1u_means001', 'A1u_means002', 'A1u_means003', 'A1u_means004', 'A1u_means005', 'A1u_means006', 'A1u_means007', 'A1u_means008', 'A1u_means009', 'A2u_mean', 'A2u_means001', 'A2u_means002', 'A2u_means003', 'A2u_means004', 'A2u_means005', 'A2u_means006', 'A2u_means007', 'A2u_means008', 'A2u_means009', 'A3u_mean', 'A3u_means001', 'A3u_means002', 'A3u_means003', 'A3u_means004', 'A3u_means005', 'A3u_means006', 'A3u_means007', 'A3u_means008', 'A3u_means009', 'H1H2u_mean', 'H1H2u_means001', 'H1H2u_means002', 'H1H2u_means003', 'H1H2u_means004', 'H1H2u_means005', 'H1H2u_means006', 'H1H2u_means007', 'H1H2u_means008', 'H1H2u_means009', 'H2H4u_mean', 'H2H4u_means001', 'H2H4u_means002', 'H2H4u_means003', 'H2H4u_means004', 'H2H4u_means005', 'H2H4u_means006', 'H2H4u_means007', 'H2H4u_means008', 'H2H4u_means009', 'H1A1u_mean', 'H1A1u_means001', 'H1A1u_means002', 'H1A1u_means003', 'H1A1u_means004', 'H1A1u_means005', 'H1A1u_means006', 'H1A1u_means007', 'H1A1u_means008', 'H1A1u_means009', 'H1A2u_mean', 'H1A2u_means001', 'H1A2u_means002', 'H1A2u_means003', 'H1A2u_means004', 'H1A2u_means005', 'H1A2u_means006', 'H1A2u_means007', 'H1A2u_means008', 'H1A2u_means009', 'H1A3u_mean', 'H1A3u_means001', 'H1A3u_means002', 'H1A3u_means003', 'H1A3u_means004', 'H1A3u_means005', 'H1A3u_means006', 'H1A3u_means007', 'H1A3u_means008', 'H1A3u_means009', 'strF0_mean', 'strF0_means001', 'strF0_means002', 'strF0_means003', 'strF0_means004', 'strF0_means005', 'strF0_means006', 'strF0_means007', 'strF0_means008', 'strF0_means009', 'sF0_mean', 'sF0_means001', 'sF0_means002', 'sF0_means003', 'sF0_means004', 'sF0_means005', 'sF0_means006', 'sF0_means007', 'sF0_means008', 'sF0_means009', 'pF0_mean', 'pF0_means001', 'pF0_means002', 'pF0_means003', 'pF0_means004', 'pF0_means005', 'pF0_means006', 'pF0_means007', 'pF0_means008', 'pF0_means009']\n"
     ]
    }
   ],
   "source": [
    "column_list = list(df.columns)\n",
    "# these are not all of the measurements, but give a good idea of what the data is presenting\n",
    "acoustic_measurements = ['H1', 'H2', 'H4', 'A1', 'A2', 'A3', 'shrF0', 'strF0', 'sF0', 'pF0']\n",
    "def in_measurements(column):\n",
    "    for a in acoustic_measurements:\n",
    "        if a in column:\n",
    "            return True\n",
    "    return False\n",
    "filtered_columns = list(filter(in_measurements, column_list))\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data splits multiple samples from the same audio file into different rows, which correspond with a word being spoken in an audio file. Each of these rows has repeated information in several columns as it stays consistent across the same speaker. The value count of each file name corresponds to how many times a word was spoken for that specific file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M24April09_shi_normal.mat    16\n",
       "F21May14_shi_normal.mat      13\n",
       "F19June26_shi_normal.mat     12\n",
       "M21May23_shi_normal.mat      12\n",
       "F22June02_shi_normal.mat     12\n",
       "                             ..\n",
       "35-vus-w_Audio.mat            1\n",
       "21-ca-w_Audio.mat             1\n",
       "23e-tawg-w_Audio.mat          1\n",
       "5-caj-w_Audio.mat             1\n",
       "M3_04_b.mat                   1\n",
       "Name: Filename, Length: 8134, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Filename'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we have several samples from one audio file, and within each of those samples, samples of the acoustic measurements at different intervals (9 to be exact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filename', '0=do not use', 'Language', 'Dialect/Village', 'Sex', 'Speaker #', 'Speaker', 'Lang_Spk', 'Phonation', 'Lphon', 'Vowel', 'Oral/Nasal', 'CorV', 'Pre_C', 'Aspiration']\n"
     ]
    }
   ],
   "source": [
    "# group by filename, which gives us many data frames for each file name\n",
    "groups = df.groupby('Filename')\n",
    "\n",
    "# this corresponds with the largest group shown by the value counts above\n",
    "largest_group_df = groups.get_group('M24April09_shi_normal.mat')\n",
    "\n",
    "# we want to get how many unique values there are for each columns\n",
    "unique_columns = largest_group_df.nunique()\n",
    "\n",
    "# this gives us a series where the values are only one\n",
    "columns_repeat = unique_columns[unique_columns == 1]\n",
    "\n",
    "# the corresponding list is the all of the columns which have repeats for every \n",
    "# row in the group\n",
    "list_columns_repeat = list(columns_repeat.index)\n",
    "print(list_columns_repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack the data\n",
    "We would like to index the data such that all of the repeat information in the columns for the same file is not repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6eab7d614ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvar_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"acoustic_means_00{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mvalue_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"means_00{i}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmelt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelt_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmelt_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mworking_additions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mworking_additions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/melt.py\u001b[0m in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mmdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_data\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \"\"\"\n\u001b[1;32m    862\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3514\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3515\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3516\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3518\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_del\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_del\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m                 \u001b[0mbml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4422\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4423\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4424\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_df = df.set_index(list_columns_repeat)\n",
    "melt_df = stacked_df\n",
    "working_additions = []\n",
    "for i in range(1,3):\n",
    "    print(i)\n",
    "    string = f'means00{i}'\n",
    "    columns = list(melt_df.columns)\n",
    "    melt_vars = [k for k in columns if string in k]\n",
    "    id_vars =[l for l in columns if l not in melt_vars]\n",
    "    id_vars = [l for l in id_vars if l not in working_additions]\n",
    "    var_name = f\"acoustic_means_00{i}\"\n",
    "    value_name = f\"means_00{i}\"\n",
    "    melt_df = pd.melt(melt_df, id_vars=id_vars, value_vars=melt_vars, var_name=var_name, value_name=value_name)\n",
    "    working_additions.append(var_name)\n",
    "    working_additions.append(value_name)\n",
    "melt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# largest_group_df_indexed\n",
    "columns = list(df.columns)\n",
    "melt_vars = [i for i in columns if 'means001' in i]\n",
    "id_vars =[l for l in columns if l not in melt_vars]\n",
    "melt_df = pd.melt(df, id_vars=id_vars)\n",
    "melt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = [f'shrF0_means00{i}' for i in range(1,10)]\n",
    "# melt_vars = ['shf_mean'] + means\n",
    "melt_vars = ['shrF0_means001']\n",
    "id_vars =[l for l in list(largest_group_df.columns) if l not in melt_vars]\n",
    "largest_group_melt_df = pd.melt(largest_group_df, id_vars=id_vars)\n",
    "largest_group_melt_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
